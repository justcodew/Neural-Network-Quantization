
作者：王小二
链接：https://zhuanlan.zhihu.com/p/462971462
来源：知乎

王小二 再读《神经网络量化白皮书》

再读《神经网络量化白皮书》- 0x00

再读《神经网络量化白皮书》- 0x01 摘要和绪论

再读《神经网络量化白皮书》- 0x02 量化的一些基础知识

再读《神经网络量化白皮书》- 0x03 训练后量化(PTQ)

再读《神经网络量化白皮书》- 0x04 训练时量化(QAT)

再读《神经网络量化白皮书》- 0x05 总结和结论

再读《神经网络量化白皮书》- 0x06 自己的碎碎念



![image](https://user-images.githubusercontent.com/107862224/194758001-baeba07d-1b01-42e6-a735-1b63bb143bbf.png)



这个系列会更新一下最近又重新看了一遍的《A White Paper on Neural Network Quantization》，系列内容以翻译为主，会适当穿插一部分自己的理解。
因为这篇文章本身就写的非常浅显易懂不需要过多的增加内容。关于文章中提到的一些技术需要展开讲的，后续可能会有其它知识补充系列来填坑。翻译比较直白和粗暴，意会即可。

这篇文章《A White Paper on Neural Network Quantization》是来自高通研究院，和之前谷歌的那篇文章名字有点像但是内容不一样。《Quantizing deep convolutional networks for efficient inference: A whitepaper》谷歌这篇文章是18年出的，大概讲了一下自家的一个量化流程和技术。高通这篇文章则是期望构建一个通用的量化流程(实际上很多内容还是来自高通自家的论文)。

系列文章的组织会基本按照原文的内容来安排，大概会有以下几个部分：
1、摘要和绪王小二：再读《神经网络量化白皮书》- 0x01 摘要和绪论 
2、量化的一些基础知识王小二：再读《神经网络量化白皮书》- 0x02 量化的一些基础知识 
3、训练后量化技术(Post-training quantization 简称 PTQ)王小二：再读《神经网络量化白皮书》- 0x03 训练后量化(PTQ) 
4、量化感知训练(Quantization-aware training 简称 QAT)，也有叫训练时量化王小二：再读《神经网络量化白皮书》- 0x04 训练时量化(QAT) 
5、总结王小二：再读《神经网络量化白皮书》- 0x05 总结和结论 
6、个人的碎碎念王小二：再读《神经网络量化白皮书》- 0x06 自己的碎碎念

整个文章一共27页PDF，除去引用部分实际只有25的PDF，内容比较浅显易懂，建议大家感兴趣的可以多读几遍。



# 再读《神经网络量化白皮书》- 0x01 摘要和绪论
一、摘要：

虽然神经网络在很多应用中取得了前沿的结果，但是它们通常需要付出非常高的计算代价。如果我们希望把一些现代化的网络应用到对功耗和计算有严格要求的边缘设备中，降低神经网络在推理过程中的能耗和延迟就非常关键。神经网络量化是实现这些需求最有效的方法之一，但是量化引起的额外噪声会导致精度的下降。在这篇白皮书中我们介绍了最先进的算法，用以减轻量化噪声对网络性能的影响，同时对权重和激活都使用低位宽表示(这里的激活不是指激活函数，而是指输入输出的特征图也就是常说的feature map)。我们首先介绍了量化的硬件动机，然后考虑两类主要的算法：训练后量化(PTQ)和量化感知训练(QAT)。PTQ不需要重新进行训练或者是标签数据，因此这是一种轻量化的量化方法。在大多数情况下PTQ在使用8bit量化时就足以接近浮点模型的精度。QAT需要微调和带标签的数据，但是可以在更低位宽时取得更有竞争力的结果。对于这两种方案，我们根据现有的文献以及大量的实验提出了测试流程，从而为常见的深度学习模型和任务带来最佳的性能。


二、绪论or简介

随着深度学习作为一种将智能注入电子设备的通用工具越来越受到大家的欢迎，小型化、低能耗、低延迟的神经网络解决方案必要性逐渐增加。如今神经网络可以再许多电子设备和服务中找到，从智能手机、智能眼镜和家用电器到无人机、机器人、自动驾驶。这些设备通常对神经网络的执行过程有着严格的时间限制或者在长期执行时对功耗有则严苛的要求。减少神经网络计算时间和能耗的最有效方法之一就是量化。在神经网络量化过程中，权重和激活通常被保存为低bit精度而不是训练时的16bit或者32bit。从32bit到8bit，存储消耗降低为原来的1/4，矩阵乘法的消耗则降低为原来的1/16。神经网络已经被证明对量化有着比较好的鲁棒性，因此它可以被量化到比较低的位宽上，但是对网络的精度影响却不大。此外，神经网络量化通常还可以和一些常见的网络优化方法一起使用例如神经网络结构搜索(NAS)、压缩(compression)、剪枝(pruning)等。在任何深度学习实例中，这都是一个提升模型效率的重要步骤。然而神经网络量化并不是没有代价的。更低的量化位宽可能给网络带来噪声，从而导致模型的精度下降。一部分网络模型对这部分噪声足够鲁棒，而有些网络模型则需要采用一些其它方案来规避这部分噪声，从而使得模型可以被量化。在这篇白皮书中我们介绍了最先进的神经网络量化技术。我们首先介绍量化、讨论硬件和实际因素。然后考虑两种不同的量化方法：训练后量化(PTQ)和量化感知训练(QAT)。PTQ方法在第三章讨论，将已经训练好的模型进行量化，同时只需要很少的数据或者不需要数据，少部分需要手动调整的超参数以及不需要端到端训练。这使得PTQ成为一种工程实现简单并且不需要大量计算成本的量化方法。作为对比在第四章讨论了QAT，它依赖神经网络在训练过程中进行模拟量化。虽然QAT需要进行重新训练以及调整超参数，但是在低bit时却可以比PTQ获得更接近全精度的效果。对于这两种方案，我们在现有文献和大量的实验基础上提出了一种标准的流程，在计算机视觉(CV)和自然语言处理(NLP)中都取得了最佳的性能。同时我们还提供了一个调试流程来解决量化过程中会碰到的一些常见问题。









